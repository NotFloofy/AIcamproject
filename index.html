<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
  <title>Mobile AI Object Detector</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <style>
    body { 
      text-align: center; 
      font-family: Arial, sans-serif; 
      margin: 0; 
      overflow: hidden; 
      background-color: #ffe6f0; 
    }
    #container { 
      position: relative; 
      width: 100vw; 
      height: 100vh; 
    }
    video { 
      width: 100%; 
      height: 100%; 
      object-fit: cover; 
      /* Removed transform to show correct orientation */
      display: none; 
    }
    canvas { 
      position: absolute; 
      top: 0; 
      left: 0; 
      width: 100%; 
      height: 100%; 
      display: none; 
    }
    #status { 
      position: absolute; 
      top: 10px; 
      left: 50%; 
      transform: translateX(-50%);
      background: rgba(0, 0, 0, 0.7); 
      color: white; 
      padding: 8px 12px; 
      border-radius: 5px; 
      z-index: 2;
    }
    #startButton {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      font-size: 18px;
      padding: 10px 20px;
      border: none;
      background-color: #ff99cc;
      color: white;
      border-radius: 8px;
      cursor: pointer;
      z-index: 2;
    }
  </style>
</head>
<body>
  <div id="container">
    <p id="status">Tap the button to allow camera access, cutie~</p>
    <button id="startButton">Start Camera :3</button>
    <video id="webcam" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
  </div>

  <script>
    const startButton = document.getElementById("startButton");
    const video = document.getElementById("webcam");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const statusText = document.getElementById("status");
    let model;

    // When the cute button is clicked, the browser's normal camera permission prompt appears!
    startButton.addEventListener("click", () => {
      navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } })
        .then(stream => {
          video.srcObject = stream;
          video.addEventListener("loadedmetadata", () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            startButton.style.display = "none";
            video.style.display = "block";
            canvas.style.display = "block";
            statusText.innerText = "Camera is on! Loading our AI model, cutie~";
            loadModel();
          });
        })
        .catch(err => {
          alert("Oops! Unable to access the camera: " + err);
        });
    });

    async function loadModel() {
      model = await cocoSsd.load();
      statusText.innerText = "Model loaded! Tap on an object to detect it, cutie~";
    }

    // When you tap on the canvas, the AI will run detection on that frame.
    canvas.addEventListener("click", async (e) => {
      // Clear any previous drawings
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      
      // Calculate tap coordinates relative to the canvas
      const rect = canvas.getBoundingClientRect();
      const scaleX = canvas.width / rect.width;
      const scaleY = canvas.height / rect.height;
      const x = (e.clientX - rect.left) * scaleX;
      const y = (e.clientY - rect.top) * scaleY;
      
      statusText.innerText = "Detecting, cutie~";
      // Run detection on the current video frame
      const predictions = await model.detect(video);
      let detected = false;
      
      predictions.forEach(prediction => {
        const [bx, by, bw, bh] = prediction.bbox;
        // Check if tap coordinates are within the bounding box
        if (x >= bx && x <= bx + bw && y >= by && y <= by + bh) {
          detected = true;
          // Draw a highlight box around the detected object
          ctx.beginPath();
          ctx.rect(bx, by, bw, bh);
          ctx.lineWidth = 3;
          ctx.strokeStyle = "lime";
          ctx.stroke();
          // Update the status with object details
          statusText.innerText = `Detected: ${prediction.class} (${Math.round(prediction.score * 100)}%)`;
        }
      });
      
      if (!detected) {
        statusText.innerText = "No object detected at that spot, cutie~";
      }
    });
  </script>
</body>
</html>
